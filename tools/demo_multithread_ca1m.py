# For licensing see accompanying LICENSE file.
# Copyright (C) 2025 Apple Inc. All Rights Reserved.
import os
os.environ["PYTORCH_ENABLE_MPS_FALLBACK"] = "1"

import argparse
import glob
import itertools
import numpy as np
import torch
import torchvision
import sys
import uuid
import time
import json
import threading
import queue
import multiprocessing
from datetime import datetime
from collections import defaultdict
from pathlib import Path
from PIL import Image
from scipy.spatial.transform import Rotation
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed

try:
    import open3d as o3d
    OPEN3D_AVAILABLE = True
    print("âœ… Open3Då¯ç”¨ï¼Œå°†ä½¿ç”¨ä½“ç´ ä¸‹é‡‡æ ·åŠŸèƒ½")
except ImportError:
    OPEN3D_AVAILABLE = False
    print("âš ï¸ Open3Dä¸å¯ç”¨ï¼Œå°†è·³è¿‡ä½“ç´ ä¸‹é‡‡æ ·")
    o3d = None

from cubifyanything.batching import Sensors
from cubifyanything.boxes import GeneralInstance3DBoxes
from cubifyanything.capture_stream import CaptureDataset
from cubifyanything.color import random_color
from cubifyanything.cubify_transformer import make_cubify_transformer
from cubifyanything.dataset import CubifyAnythingDataset
from cubifyanything.instances import Instances3D
from cubifyanything.preprocessor import Augmentor, Preprocessor

class TimingStats:
    """è€—æ—¶ç»Ÿè®¡ç±»"""
    def __init__(self):
        self.timing_data = defaultdict(list)
        self.step_times = {}
        self.frame_times = []
        self.start_time = None
    
    def start_timer(self, step_name):
        """å¼€å§‹è®¡æ—¶"""
        self.step_times[step_name] = time.time()
    
    def end_timer(self, step_name):
        """ç»“æŸè®¡æ—¶å¹¶è®°å½•"""
        if step_name in self.step_times:
            elapsed = time.time() - self.step_times[step_name]
            self.timing_data[step_name].append(elapsed)
            del self.step_times[step_name]
            return elapsed
        return 0
    
    def start_total_timer(self):
        """å¼€å§‹æ€»è®¡æ—¶"""
        self.start_time = time.time()
    
    def end_total_timer(self):
        """ç»“æŸæ€»è®¡æ—¶"""
        if self.start_time is not None:
            total_time = time.time() - self.start_time
            self.timing_data['total_processing'].append(total_time)
            return total_time
        return 0
    
    def add_frame_time(self, frame_time):
        """æ·»åŠ å•å¸§å¤„ç†æ—¶é—´"""
        self.frame_times.append(frame_time)
    
    def get_stats(self, step_name):
        """è·å–æŸä¸ªæ­¥éª¤çš„ç»Ÿè®¡ä¿¡æ¯"""
        times = self.timing_data[step_name]
        if not times:
            return {'count': 0, 'total': 0, 'avg': 0, 'min': 0, 'max': 0}
        return {
            'count': len(times),
            'total': sum(times),
            'avg': sum(times) / len(times),
            'min': min(times),
            'max': max(times)
        }
    
    def print_summary(self):
        """æ‰“å°è€—æ—¶ç»Ÿè®¡æ±‡æ€»"""
        print("\n" + "="*80)
        print("â±ï¸  è€—æ—¶ç»Ÿè®¡æ±‡æ€»æŠ¥å‘Š")
        print("="*80)
        
        # è®¡ç®—æ€»æ—¶é—´
        total_stats = self.get_stats('total_processing')
        if total_stats['count'] > 0:
            print(f"ğŸ•’ æ€»å¤„ç†æ—¶é—´: {total_stats['total']:.2f}ç§’")
        
        if self.frame_times:
            print(f"ğŸ“Š å¤„ç†å¸§æ•°: {len(self.frame_times)}")
            print(f"âš¡ å¹³å‡æ¯å¸§æ—¶é—´: {sum(self.frame_times)/len(self.frame_times):.3f}ç§’")
            print(f"ğŸš€ æœ€å¿«å¸§: {min(self.frame_times):.3f}ç§’")
            print(f"ğŸŒ æœ€æ…¢å¸§: {max(self.frame_times):.3f}ç§’")
            print(f"âš¡ å¹³å‡FPS: {len(self.frame_times)/sum(self.frame_times):.2f}")
        
        print("\nğŸ“‹ å„æ­¥éª¤è€—æ—¶è¯¦æƒ…:")
        print("-" * 80)
        
        # æŒ‰æ€»è€—æ—¶æ’åºæ˜¾ç¤ºå„æ­¥éª¤
        step_totals = []
        for step_name in self.timing_data:
            if step_name != 'total_processing':
                stats = self.get_stats(step_name)
                if stats['count'] > 0:
                    step_totals.append((step_name, stats))
        
        step_totals.sort(key=lambda x: x[1]['total'], reverse=True)
        
        for step_name, stats in step_totals:
            total_time = stats['total']
            avg_time = stats['avg']
            count = stats['count']
            min_time = stats['min']
            max_time = stats['max']
            
            print(f"{step_name:30} | "
                  f"æ€»è®¡: {total_time:7.2f}s | "
                  f"æ¬¡æ•°: {count:4d} | "
                  f"å¹³å‡: {avg_time:6.3f}s | "
                  f"æœ€å°: {min_time:6.3f}s | "
                  f"æœ€å¤§: {max_time:6.3f}s")
        
        print("="*80)

class TaskQueue:
    """ä»»åŠ¡é˜Ÿåˆ—ç®¡ç†å™¨"""
    def __init__(self, compute_workers=4, io_workers=2):
        self.compute_queue = queue.Queue()
        self.io_queue = queue.Queue()
        self.compute_workers = compute_workers
        self.io_workers = io_workers
        self.shutdown = False
        
    def add_compute_task(self, task):
        """æ·»åŠ è®¡ç®—ä»»åŠ¡"""
        self.compute_queue.put(task)
    
    def add_io_task(self, task):
        """æ·»åŠ I/Oä»»åŠ¡"""
        self.io_queue.put(task)
    
    def stop(self):
        """åœæ­¢ä»»åŠ¡é˜Ÿåˆ—"""
        self.shutdown = True

class ThreadSafeWriter:
    """çº¿ç¨‹å®‰å…¨çš„æ–‡ä»¶å†™å…¥å™¨"""
    def __init__(self):
        self.lock = threading.Lock()
    
    def write_ply(self, points, colors, filename):
        """çº¿ç¨‹å®‰å…¨åœ°å†™å…¥PLYæ–‡ä»¶"""
        with self.lock:
            save_pointcloud_ply(points, colors, filename)
    
    def write_nocs_image(self, nocs_image, filename):
        """çº¿ç¨‹å®‰å…¨åœ°å†™å…¥NOCSå›¾åƒ"""
        with self.lock:
            nocs_image_pil = Image.fromarray(nocs_image)
            nocs_image_pil.save(filename)

def extract_bbox_info_from_instances(gt_instances):
    """ä»gt_instancesä¸­æå–bboxä¿¡æ¯"""
    if not gt_instances.has("gt_boxes_3d") or not gt_instances.has("gt_ids"):
        print("âš ï¸ è­¦å‘Š: instancesä¸­ç¼ºå°‘gt_boxes_3dæˆ–gt_idså­—æ®µ")
        return {}
    
    boxes_3d = gt_instances.get("gt_boxes_3d")
    instance_ids = gt_instances.get("gt_ids")
    
    print(f"ğŸ“Š æå–bboxä¿¡æ¯: å‘ç° {len(instance_ids)} ä¸ªå®ä¾‹")
    if len(instance_ids) > 0:
        print(f"ğŸ“‹ Instance IDç¤ºä¾‹: {instance_ids[0]} (ç±»å‹: {type(instance_ids[0])})")
    
    bbox_info = {}
    centers = boxes_3d.gravity_center.cpu().numpy()
    rotations = boxes_3d.R.cpu().numpy()
    dims = boxes_3d.dims.cpu().numpy()
    
    for i in range(len(boxes_3d)):
        # ä¿æŒåŸå§‹instance_idæ ¼å¼ï¼Œæ— è®ºæ˜¯intè¿˜æ˜¯string
        instance_id = instance_ids[i]
        # å¯¹äºJSONåºåˆ—åŒ–ï¼Œç¡®ä¿ä½¿ç”¨å­—ç¬¦ä¸²æ ¼å¼
        instance_key = str(instance_id)
        bbox_info[instance_key] = {
            'center': centers[i],
            'rotation': rotations[i],
            'dimensions': dims[i],
            'corners': boxes_3d.corners[i].cpu().numpy()
        }
    
    return bbox_info

def save_bbox_info(bbox_info, filename):
    """ä¿å­˜bboxä¿¡æ¯åˆ°JSONæ–‡ä»¶"""
    # è½¬æ¢numpyæ•°ç»„ä¸ºåˆ—è¡¨ä»¥ä¾¿JSONåºåˆ—åŒ–
    serializable_bbox_info = {}
    for instance_id, info in bbox_info.items():
        serializable_bbox_info[instance_id] = {
            'center': info['center'].tolist(),
            'rotation': info['rotation'].tolist(),
            'dimensions': info['dimensions'].tolist(),
            'corners': info['corners'].tolist()
        }
    
    with open(filename, 'w') as f:
        json.dump(serializable_bbox_info, f, indent=2)

def save_pointcloud_ply(points, colors, filename):
    """å°†ç‚¹äº‘ä¿å­˜ä¸ºPLYæ–‡ä»¶"""
    if colors.max() <= 1.0:
        colors = (colors * 255).astype(np.uint8)
    else:
        colors = colors.astype(np.uint8)
    
    with open(filename, 'w') as f:
        f.write("ply\n")
        f.write("format ascii 1.0\n")
        f.write(f"element vertex {len(points)}\n")
        f.write("property float x\n")
        f.write("property float y\n")
        f.write("property float z\n")
        f.write("property uchar red\n")
        f.write("property uchar green\n")
        f.write("property uchar blue\n")
        f.write("end_header\n")
        
        for i in range(len(points)):
            point = points[i]
            color = colors[i]
            f.write(f"{point[0]} {point[1]} {point[2]} {color[0]} {color[1]} {color[2]}\n")

def collect_instance_pointclouds(points_3d, colors, gt_instances, frame_num, instance_pointclouds):
    """æŒ‰instance IDæ”¶é›†ç‚¹äº‘ç”¨äºç´¯ç§¯"""

    if not gt_instances.has("gt_boxes_3d") or not gt_instances.has("gt_ids"):
        print("Warning: No gt_boxes_3d or gt_ids field found in instances")
        return

    boxes_3d = gt_instances.get("gt_boxes_3d")
    instance_ids = gt_instances.get("gt_ids")
    corners = boxes_3d.corners.cpu().numpy()
    centers = boxes_3d.gravity_center.cpu().numpy()
    rotations = boxes_3d.R.cpu().numpy()
    dims = boxes_3d.dims.cpu().numpy()
    
    for i in range(len(boxes_3d)):
        instance_id = str(instance_ids[i])  # ç¡®ä¿ä¸ºå­—ç¬¦ä¸²æ ¼å¼
        box_corners = corners[i]
        box_center = centers[i]
        box_rotation = rotations[i]
        box_dims = dims[i]

        in_box_mask = points_in_box(points_3d, box_corners)

        point_count = np.sum(in_box_mask)

        if point_count > 0:
            instance_points = points_3d[in_box_mask]
            instance_colors = colors[in_box_mask]

            if instance_id not in instance_pointclouds:
                instance_pointclouds[instance_id] = {
                    'pointcloud_frames': [],
                    'reference_bbox': None
                }

            if instance_pointclouds[instance_id]['reference_bbox'] is None:
                instance_pointclouds[instance_id]['reference_bbox'] = {
                    'center': box_center,
                    'rotation': box_rotation,
                    'dims': box_dims,
                    'reference_frame': frame_num
                }
                print(f"ğŸ¯ è®¾ç½®instance {instance_id}çš„å‚è€ƒbbox (æ¥è‡ªå¸§{frame_num})")

            instance_pointclouds[instance_id]['pointcloud_frames'].append({
                'points': instance_points,
                'colors': instance_colors,
                'frame': frame_num,
                'current_bbox': {
                    'center': box_center,
                    'rotation': box_rotation,
                    'dims': box_dims
                }
            })

            print(f"Collected {point_count} points for instance {instance_id} in frame {frame_num}")

def downsample_pointcloud_with_open3d(points, colors, voxel_size=0.004):
    """ä½¿ç”¨Open3Dè¿›è¡Œä½“ç´ ä¸‹é‡‡æ ·"""
    if not OPEN3D_AVAILABLE:
        print(f"âš ï¸ Open3Dä¸å¯ç”¨ï¼Œè·³è¿‡ä¸‹é‡‡æ ·ï¼Œä¿ç•™åŸå§‹ {len(points):,} ä¸ªç‚¹")
        return points, colors
        
    try:
        # åˆ›å»ºOpen3Dç‚¹äº‘å¯¹è±¡
        pcd = o3d.geometry.PointCloud()
        pcd.points = o3d.utility.Vector3dVector(points)
        pcd.colors = o3d.utility.Vector3dVector(colors)
        
        # ä½“ç´ ä¸‹é‡‡æ ·
        original_count = len(pcd.points)
        downsampled_pcd = pcd.voxel_down_sample(voxel_size=voxel_size)
        downsampled_count = len(downsampled_pcd.points)
        
        # è½¬æ¢å›numpyæ•°ç»„
        downsampled_points = np.asarray(downsampled_pcd.points)
        downsampled_colors = np.asarray(downsampled_pcd.colors)
        
        reduction_ratio = (original_count - downsampled_count) / original_count * 100
        print(f"ğŸ“¦ ä½“ç´ ä¸‹é‡‡æ ·: {original_count:,} -> {downsampled_count:,} ç‚¹ "
              f"(å‡å°‘ {reduction_ratio:.1f}%, ä½“ç´ å¤§å°: {voxel_size}m)")
        
        return downsampled_points, downsampled_colors
        
    except Exception as e:
        print(f"âŒ Open3Dä¸‹é‡‡æ ·å¤±è´¥: {e}")
        print(f"ğŸ”„ å›é€€åˆ°åŸå§‹ç‚¹äº‘: {len(points):,} ä¸ªç‚¹")
        return points, colors

def compute_normalized_pointcloud(instance_id, instance_data, voxel_size):
    """è®¡ç®—å½’ä¸€åŒ–ç‚¹äº‘ï¼ˆçº¯è®¡ç®—ä»»åŠ¡ï¼‰"""
    if not instance_data or 'pointcloud_frames' not in instance_data:
        return None
        
    pointcloud_frames = instance_data['pointcloud_frames']
    reference_bbox = instance_data['reference_bbox']
    
    if not pointcloud_frames or not reference_bbox:
        print(f"âš ï¸ Instance {instance_id}: ç¼ºå°‘ç‚¹äº‘æ•°æ®æˆ–å‚è€ƒbbox")
        return None
    
    print(f"ğŸ¯ [è®¡ç®—] å¤„ç†Instance {instance_id}: {len(pointcloud_frames)} å¸§")
    
    ref_center = reference_bbox['center']
    ref_rotation = reference_bbox['rotation'] 
    ref_dims = reference_bbox['dims']
    
    all_normalized_points = []
    all_colors = []
    
    # å½’ä¸€åŒ–å¤„ç†
    for frame_data in pointcloud_frames:
        frame_points = frame_data['points']
        frame_colors = frame_data['colors']
        frame_num = frame_data['frame']
        
        normalized_points, normalized_colors = compute_nocs_with_bbox_orientation(
            frame_points, ref_center, ref_rotation, ref_dims, f"{instance_id}_frame_{frame_num}")
        
        all_normalized_points.append(normalized_points)
        all_colors.append(frame_colors)
    
    if all_normalized_points:
        # åˆå¹¶æ‰€æœ‰å½’ä¸€åŒ–ç‚¹äº‘
        final_normalized_points = np.concatenate(all_normalized_points, axis=0)
        final_colors = np.concatenate(all_colors, axis=0)
        
        # ä¸‹é‡‡æ ·ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if voxel_size > 0:
            downsampled_points, downsampled_colors = downsample_pointcloud_with_open3d(
                final_normalized_points, final_colors, voxel_size)
        else:
            downsampled_points, downsampled_colors = final_normalized_points, final_colors
        
        return instance_id, downsampled_points, downsampled_colors
    
    return None

def save_pointcloud_task(result, output_dir):
    """ä¿å­˜ç‚¹äº‘ä»»åŠ¡ï¼ˆçº¯I/Oæ“ä½œï¼‰"""
    if result is None:
        return
    
    instance_id, points, colors = result
    objects_dir = os.path.join(output_dir, "objects")
    os.makedirs(objects_dir, exist_ok=True)
    
    normalized_file = os.path.join(objects_dir, f"instance_{instance_id}.ply")
    save_pointcloud_ply(points, colors, normalized_file)
    print(f"ğŸ’¾ [I/O] ä¿å­˜instance {instance_id}å½’ä¸€åŒ–ç‚¹äº‘: {normalized_file}")

def save_normalized_instance_pointcloud_threaded(instance_id, instance_data, output_dir, voxel_size, writer):
    """å¤šçº¿ç¨‹ä¿å­˜å½’ä¸€åŒ–å®ä¾‹ç‚¹äº‘ï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰"""
    result = compute_normalized_pointcloud(instance_id, instance_data, voxel_size)
    if result:
        save_pointcloud_task(result, output_dir)

def generate_nocs_image_threaded(frame_data, writer):
    """å¤šçº¿ç¨‹ç”ŸæˆNOCSå›¾åƒ"""
    xyzrgb, world_gt_instances, depth_shape, pixel_coords_valid, frame_count, nocs_dir = frame_data
    
    if world_gt_instances is None or len(world_gt_instances) == 0:
        return
    
    # ç”ŸæˆNOCSå›¾
    nocs_image = generate_instance_nocs_map(
        xyzrgb[..., :3],
        world_gt_instances,
        None, None,  # ä¸ä½¿ç”¨ç›¸æœºå‚æ•°
        depth_shape,
        pixel_coords=pixel_coords_valid
    )
    
    # ä¿å­˜NOCSå›¾åƒ
    if nocs_image is not None:
        nocs_file = os.path.join(nocs_dir, f"frame_{frame_count:04d}_nocs.png")
        writer.write_nocs_image(nocs_image, nocs_file)
        print(f"ğŸ’¾ [çº¿ç¨‹] ä¿å­˜NOCSå›¾: {nocs_file}")

def generate_instance_nocs_map(points_3d, gt_instances, camera_K, camera_RT, image_shape, pixel_coords=None):
    """ä¸ºæ¯å¸§ä¸­æ£€æµ‹åˆ°çš„æ‰€æœ‰ç‰©ä½“ç”ŸæˆNOCSå›¾"""
    if gt_instances is None or len(gt_instances) == 0:
        return None
    
    height, width = image_shape
    
    if points_3d.ndim == 3 and points_3d.shape[:2] == (height, width):
        print(f"ğŸ“ è¾“å…¥ç‚¹äº‘æ ¼å¼: {points_3d.shape} - ä¿æŒåƒç´ å¯¹åº”å…³ç³»")
        points_3d_reshaped = points_3d.reshape(-1, 3)
        
        v_coords, u_coords = np.mgrid[0:height, 0:width]
        pixel_u = u_coords.flatten()
        pixel_v = v_coords.flatten()
        
        valid_mask = np.isfinite(points_3d_reshaped).all(axis=1) & (np.linalg.norm(points_3d_reshaped, axis=1) > 0.01)
        
    elif points_3d.ndim == 2:
        if pixel_coords is None:
            print("âŒ é”™è¯¯: (N, 3) æ ¼å¼çš„ç‚¹äº‘éœ€è¦æä¾›pixel_coordså‚æ•°")
            return None
        
        points_3d_reshaped = points_3d
        pixel_u = pixel_coords[:, 0]
        pixel_v = pixel_coords[:, 1]
        
        valid_mask = (pixel_u >= 0) & (pixel_u < width) & (pixel_v >= 0) & (pixel_v < height) & \
                    np.isfinite(points_3d_reshaped).all(axis=1) & (np.linalg.norm(points_3d_reshaped, axis=1) > 0.01)
    else:
        print(f"âŒ é”™è¯¯: ä¸æ”¯æŒçš„ç‚¹äº‘æ ¼å¼ {points_3d.shape}")
        return None
    
    points_3d_valid = points_3d_reshaped[valid_mask]
    pixel_u_valid = pixel_u[valid_mask]
    pixel_v_valid = pixel_v[valid_mask]
    
    if len(points_3d_valid) == 0:
        print("âš ï¸ æ²¡æœ‰æœ‰æ•ˆçš„3Dç‚¹")
        return None
    
    nocs_image = np.zeros((height, width, 3), dtype=np.float32)
    
    if gt_instances.has("gt_boxes_3d"):
        boxes_3d = gt_instances.get("gt_boxes_3d")
    else:
        print(f"âŒ é”™è¯¯: åœ¨instancesä¸­æœªæ‰¾åˆ°gt_boxes_3då­—æ®µ")
        return None
        
    corners = boxes_3d.corners.cpu().numpy()
    rotations = boxes_3d.R.cpu().numpy()
    centers = boxes_3d.gravity_center.cpu().numpy()
    dims = boxes_3d.dims.cpu().numpy()
    
    for i in range(len(boxes_3d)):
        box_corners = corners[i]
        box_rotation = rotations[i]
        box_center = centers[i]
        box_dims = dims[i]
        
        in_box_mask = points_in_box(points_3d_valid, box_corners)
        
        point_count = np.sum(in_box_mask)
        
        if point_count > 0:
            instance_points = points_3d_valid[in_box_mask]
            instance_u = pixel_u_valid[in_box_mask]
            instance_v = pixel_v_valid[in_box_mask]
            
            nocs_points, nocs_colors = compute_nocs_with_bbox_orientation(
                instance_points, box_center, box_rotation, box_dims, i)
            
            nocs_image[instance_v, instance_u] = nocs_colors
    
    if np.any(nocs_image > 0):
        nocs_image_display = (np.clip(nocs_image, 0, 1) * 255).astype(np.uint8)
        return nocs_image_display
    else:
        return None

def compute_nocs_with_bbox_orientation(points, box_center, box_rotation, box_dims, instance_id):
    """ä½¿ç”¨bboxçš„å®Œæ•´ä¿¡æ¯è®¡ç®—NOCSå˜æ¢"""
    centered_points = points - box_center
    local_points = centered_points @ box_rotation
    max_dim = np.max(box_dims)
    nocs_points = local_points / max_dim
    nocs_points = np.clip(nocs_points, -0.5, 0.5)
    nocs_colors = np.clip(nocs_points + 0.5, 0, 1)
    
    return nocs_points, nocs_colors

def points_in_box(points, corners):
    """æ£€æŸ¥ç‚¹æ˜¯å¦åœ¨è¾¹ç•Œæ¡†å†…"""
    min_bound = np.min(corners, axis=0)
    max_bound = np.max(corners, axis=0)
    in_box = np.all((points >= min_bound) & (points <= max_bound), axis=1)
    
    return in_box

def get_camera_coords(depth):
    height, width = depth.shape
    device = depth.device

    camera_coords = torch.stack(
        torch.meshgrid(
            torch.arange(0, width, device=device),
            torch.arange(0, height, device=device), indexing="xy"),
        dim=-1)

    return camera_coords

def unproject(depth, K, RT, max_depth=10.0):
    camera_coords = get_camera_coords(depth) * depth[..., None]

    intrinsics_4x4 = torch.eye(4, device=depth.device)
    intrinsics_4x4[:3, :3] = K

    valid = depth > 0
    if max_depth is not None:
        valid &= (depth < max_depth)

    depth = depth[..., None]
    uvd = torch.cat((camera_coords, depth, torch.ones_like(depth)), dim=-1)

    camera_xyz =  torch.linalg.inv(intrinsics_4x4) @ uvd.view(-1, 4).T
    world_xyz = RT @ camera_xyz

    return world_xyz.T[..., :-1].reshape(uvd.shape[0], uvd.shape[1], 3), valid

def process_single_scene(scene_path, output_base_dir, voxel_size=0.004, compute_workers=4, io_workers=2):
    """å¤„ç†å•ä¸ªåœºæ™¯çš„æ•°æ®ï¼Œä½¿ç”¨åˆ†ç¦»çš„è®¡ç®—å’ŒI/Oçº¿ç¨‹æ± """
    scene_name = Path(scene_path).stem
    print(f"\nğŸ¬ å¼€å§‹å¤„ç†åœºæ™¯: {scene_name}")
    
    # åˆ›å»ºåœºæ™¯è¾“å‡ºç›®å½•
    scene_output_dir = os.path.join(output_base_dir, scene_name)
    os.makedirs(scene_output_dir, exist_ok=True)
    
    nocs_dir = os.path.join(scene_output_dir, "nocs_images")
    objects_dir = os.path.join(scene_output_dir, "objects")
    os.makedirs(nocs_dir, exist_ok=True)
    os.makedirs(objects_dir, exist_ok=True)
    
    # åˆå§‹åŒ–è€—æ—¶ç»Ÿè®¡
    timing_stats = TimingStats()
    timing_stats.start_total_timer()
    
    # åˆ›å»ºæ•°æ®é›†
    dataset = CubifyAnythingDataset(
        [Path(scene_path).as_uri()],
        yield_world_instances=True,
        load_arkit_depth=True,
        use_cache=False
    )
    
    frame_count = 0
    instance_pointclouds = {}
    scene_bbox_info = {}
    writer = ThreadSafeWriter()
    
    # æ”¶é›†NOCSç”Ÿæˆä»»åŠ¡
    nocs_tasks = []
    
    for sample in dataset:
        frame_start_time = time.time()
        frame_count += 1
        
        if frame_count % 10 == 0:
            print(f"ğŸ“Š å¤„ç†åœºæ™¯ {scene_name} ç¬¬ {frame_count} å¸§...")
        
        # æ£€æŸ¥æ•°æ®ç»“æ„
        if "wide" not in sample or "image" not in sample["wide"]:
            continue
        
        # æ•°æ®åŠ è½½
        timing_stats.start_timer('data_loading')
        image = np.moveaxis(sample["wide"]["image"][-1].numpy(), 0, -1)        
        timing_stats.end_timer('data_loading')
        
        # å¤„ç†æ·±åº¦æ•°æ®
        if "gt" in sample and sample["gt"] is not None and "depth" in sample["gt"]:
            timing_stats.start_timer('depth_unprojection')
            depth_gt = sample["gt"]["depth"][-1]
            matched_image = torch.tensor(np.array(Image.fromarray(image).resize((depth_gt.shape[1], depth_gt.shape[0]))))
            
            RT_camera_to_world = sample["sensor_info"].gt.RT[-1]
            xyz, valid = unproject(depth_gt, sample["sensor_info"].gt.depth.K[-1], RT_camera_to_world, max_depth=10.0)
            xyzrgb = torch.cat((xyz, matched_image / 255.0), dim=-1)[valid]
            
            height, width = depth_gt.shape[-2:]
            v_coords, u_coords = torch.meshgrid(torch.arange(height), torch.arange(width), indexing='ij')
            pixel_coords = torch.stack([u_coords, v_coords], dim=-1)
            pixel_coords_valid = pixel_coords[valid]
            timing_stats.end_timer('depth_unprojection')
            
            if len(xyzrgb) > 0:
                # GTå®ä¾‹å¤„ç†
                timing_stats.start_timer('gt_instance_processing')
                world_gt_instances = None
                
                if "world_instances_3d" in sample and sample["world_instances_3d"] is not None:
                    world_gt_instances = sample["world_instances_3d"]
                elif "world" in sample and "instances" in sample["world"]:
                    world_gt_instances = sample["world"]["instances"]
                elif "wide" in sample and "instances" in sample["wide"]:
                    gt_instances = sample["wide"]["instances"]
                    world_gt_instances = gt_instances.clone()
                    
                    if world_gt_instances.has("gt_boxes_3d"):
                        original_boxes = world_gt_instances.get("gt_boxes_3d")
                        RT_np = RT_camera_to_world.numpy()
                        
                        centers = original_boxes.gravity_center.cpu().numpy()
                        centers_homogeneous = np.concatenate([centers, np.ones((centers.shape[0], 1))], axis=1)
                        transformed_centers = (RT_np @ centers_homogeneous.T).T[:, :3]
                        
                        transformed_R = RT_np[:3, :3] @ original_boxes.R.cpu().numpy()
                        transformed_boxes = GeneralInstance3DBoxes(
                            np.concatenate([transformed_centers, original_boxes.dims.cpu().numpy()], axis=1),
                            transformed_R
                        )
                        
                        world_gt_instances.set("gt_boxes_3d", transformed_boxes)
                
                timing_stats.end_timer('gt_instance_processing')
                
                if world_gt_instances is not None and len(world_gt_instances) > 0:
                    # æ”¶é›†bboxä¿¡æ¯ï¼ˆä»…ç¬¬ä¸€å¸§ï¼‰
                    if frame_count == 1:
                        scene_bbox_info = extract_bbox_info_from_instances(world_gt_instances)
                    
                    # æ·»åŠ NOCSç”Ÿæˆä»»åŠ¡
                    nocs_tasks.append((
                        xyzrgb.cpu().numpy(),
                        world_gt_instances,
                        depth_gt.shape[-2:],
                        pixel_coords_valid.cpu().numpy(),
                        frame_count,
                        nocs_dir
                    ))
                    
                    # å®ä¾‹ç‚¹äº‘æ”¶é›†
                    timing_stats.start_timer('instance_pointcloud_collection')
                    collect_instance_pointclouds(
                        xyzrgb[..., :3].cpu().numpy(),
                        xyzrgb[..., 3:].cpu().numpy(),
                        world_gt_instances,
                        frame_count,
                        instance_pointclouds
                    )
                    timing_stats.end_timer('instance_pointcloud_collection')
        
        # è®°å½•å•å¸§å¤„ç†æ—¶é—´
        frame_time = time.time() - frame_start_time
        timing_stats.add_frame_time(frame_time)
    
    # åˆ†ç¦»å¼å¤šçº¿ç¨‹å¤„ç†ï¼šè®¡ç®—ä¸I/Oåˆ†ç¦»
    print(f"ğŸ”„ å¼€å§‹åˆ†ç¦»å¼å¤„ç†: {len(nocs_tasks)} ä¸ªNOCSä»»åŠ¡, {len(instance_pointclouds)} ä¸ªç‚¹äº‘ä»»åŠ¡")
    
    # 1. å¤šçº¿ç¨‹ç”ŸæˆNOCSå›¾åƒï¼ˆä¸»è¦æ˜¯I/Oï¼‰
    timing_stats.start_timer('nocs_generation')
    with ThreadPoolExecutor(max_workers=io_workers, thread_name_prefix="NOCS-IO") as nocs_executor:
        nocs_futures = [nocs_executor.submit(generate_nocs_image_threaded, task, writer) for task in nocs_tasks]
        for future in as_completed(nocs_futures):
            try:
                future.result()
            except Exception as e:
                print(f"âŒ NOCSç”Ÿæˆå¤±è´¥: {e}")
    timing_stats.end_timer('nocs_generation')
    
    # 2. åˆ†ç¦»å¼å¤„ç†å½’ä¸€åŒ–å®ä¾‹ç‚¹äº‘
    if instance_pointclouds:
        print(f"ğŸ§® å¼€å§‹è®¡ç®— {len(instance_pointclouds)} ä¸ªå½’ä¸€åŒ–ç‚¹äº‘...")
        
        # è®¡ç®—é˜¶æ®µï¼šä½¿ç”¨è®¡ç®—çº¿ç¨‹æ± 
        timing_stats.start_timer('pointcloud_computation')
        computed_results = []
        with ThreadPoolExecutor(max_workers=compute_workers, thread_name_prefix="Compute") as compute_executor:
            compute_futures = []
            for instance_id, instance_data in instance_pointclouds.items():
                future = compute_executor.submit(
                    compute_normalized_pointcloud,
                    instance_id, instance_data, voxel_size
                )
                compute_futures.append(future)
            
            for future in as_completed(compute_futures):
                try:
                    result = future.result()
                    if result:
                        computed_results.append(result)
                except Exception as e:
                    print(f"âŒ ç‚¹äº‘è®¡ç®—å¤±è´¥: {e}")
        timing_stats.end_timer('pointcloud_computation')
        
        # I/Oé˜¶æ®µï¼šä½¿ç”¨I/Oçº¿ç¨‹æ± 
        print(f"ğŸ’¾ å¼€å§‹ä¿å­˜ {len(computed_results)} ä¸ªç‚¹äº‘æ–‡ä»¶...")
        timing_stats.start_timer('pointcloud_io')
        with ThreadPoolExecutor(max_workers=io_workers, thread_name_prefix="IO") as io_executor:
            io_futures = []
            for result in computed_results:
                future = io_executor.submit(save_pointcloud_task, result, scene_output_dir)
                io_futures.append(future)
            
            for future in as_completed(io_futures):
                try:
                    future.result()
                except Exception as e:
                    print(f"âŒ ç‚¹äº‘ä¿å­˜å¤±è´¥: {e}")
        timing_stats.end_timer('pointcloud_io')
    
    # ä¿å­˜åœºæ™¯bboxä¿¡æ¯
    if scene_bbox_info:
        bbox_file = os.path.join(scene_output_dir, "scene_bbox_info.json")
        save_bbox_info(scene_bbox_info, bbox_file)
        print(f"ğŸ“Š ä¿å­˜åœºæ™¯bboxä¿¡æ¯: {bbox_file}")
    
    # ç»“æŸæ€»è®¡æ—¶
    total_time = timing_stats.end_total_timer()
    
    print(f"\nâœ… åœºæ™¯ {scene_name} å¤„ç†å®Œæˆï¼")
    print(f"ğŸ“Š æ€»å…±å¤„ç†äº† {frame_count} å¸§ï¼Œè€—æ—¶ {total_time:.2f}ç§’")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {scene_output_dir}")
    if instance_pointclouds:
        print(f"ğŸ¯ ä¿å­˜äº† {len(instance_pointclouds)} ä¸ªå½’ä¸€åŒ–å®ä¾‹ç‚¹äº‘")
    
    # æ‰“å°è¯¦ç»†çš„è€—æ—¶ç»Ÿè®¡
    timing_stats.print_summary()
    
    return scene_name, total_time, frame_count, len(instance_pointclouds)

def get_scene_files(data_dir, split, worker_id=None, total_workers=None):
    """è·å–æŒ‡å®šsplitçš„åœºæ™¯æ–‡ä»¶åˆ—è¡¨ï¼Œæ”¯æŒåˆ†å¸ƒå¼å¤„ç†"""
    split_dir = os.path.join(data_dir, split)
    if not os.path.exists(split_dir):
        raise ValueError(f"Splitç›®å½•ä¸å­˜åœ¨: {split_dir}")
    
    scene_files = glob.glob(os.path.join(split_dir, "ca1m-*.tar"))
    if len(scene_files) == 0:
        raise ValueError(f"åœ¨ {split_dir} ä¸­æœªæ‰¾åˆ°ä»»ä½•ca1m-*.taræ–‡ä»¶")
    
    scene_files = sorted(scene_files)
    
    # åˆ†å¸ƒå¼å¤„ç†ï¼šå°†æ–‡ä»¶åˆ†é…ç»™ä¸åŒçš„worker
    if worker_id is not None and total_workers is not None:
        if worker_id >= total_workers or worker_id < 0:
            raise ValueError(f"worker_id {worker_id} å¿…é¡»åœ¨ 0 åˆ° {total_workers-1} ä¹‹é—´")
        
        # è®¡ç®—å½“å‰workeréœ€è¦å¤„ç†çš„æ–‡ä»¶
        files_per_worker = len(scene_files) // total_workers
        remaining_files = len(scene_files) % total_workers
        
        start_idx = worker_id * files_per_worker + min(worker_id, remaining_files)
        if worker_id < remaining_files:
            end_idx = start_idx + files_per_worker + 1
        else:
            end_idx = start_idx + files_per_worker
        
        worker_scene_files = scene_files[start_idx:end_idx]
        
        print(f"ğŸ“ Worker {worker_id}/{total_workers}: åœ¨ {split} é›†ä¸­åˆ†é…åˆ° {len(worker_scene_files)} ä¸ªåœºæ™¯æ–‡ä»¶")
        print(f"ğŸ“Š å¤„ç†èŒƒå›´: {start_idx} - {end_idx-1} (æ€»å…± {len(scene_files)} ä¸ªæ–‡ä»¶)")
        
        return worker_scene_files
    else:
        print(f"ğŸ“ åœ¨ {split} é›†ä¸­å‘ç° {len(scene_files)} ä¸ªåœºæ™¯æ–‡ä»¶")
        return scene_files

def main():
    parser = argparse.ArgumentParser(description="CA-1Mæ•°æ®é›†åˆ†å¸ƒå¼å¤šçº¿ç¨‹å¤„ç†å·¥å…·")
    parser.add_argument("--data-dir", default="/baai-cwm-vepfs/cwm/chongjie.ye/data/CA-1M/data", 
                       help="CA-1Mæ•°æ®é›†æ ¹ç›®å½•è·¯å¾„")
    parser.add_argument("--output-dir", default="/baai-cwm-vepfs/cwm/chongjie.ye/data/CA-1M_output",
                       help="è¾“å‡ºç›®å½•è·¯å¾„")
    parser.add_argument("--split", choices=["train", "val"], required=True,
                       help="é€‰æ‹©å¤„ç†çš„æ•°æ®é›†åˆ’åˆ†")
    parser.add_argument("--voxel-size", type=float, default=0.004,
                       help="ä½“ç´ ä¸‹é‡‡æ ·å°ºå¯¸")
    parser.add_argument("--disable-downsampling", action="store_true",
                       help="ç¦ç”¨ä½“ç´ ä¸‹é‡‡æ ·")
    
    # åˆ†å¸ƒå¼å¤„ç†å‚æ•°
    parser.add_argument("--worker-id", type=int, default=None,
                       help="å½“å‰workerçš„ID (0å¼€å§‹)")
    parser.add_argument("--total-workers", type=int, default=None,
                       help="æ€»workeræ•°é‡")
    
    # çº¿ç¨‹é…ç½®å‚æ•°
    parser.add_argument("--compute-workers", type=int, default=4,
                       help="è®¡ç®—çº¿ç¨‹æ•°")
    parser.add_argument("--io-workers", type=int, default=2,
                       help="I/Oçº¿ç¨‹æ•°")
    parser.add_argument("--scene-workers", type=int, default=2,
                       help="åœºæ™¯å¤„ç†çº¿ç¨‹æ•°")
    parser.add_argument("--max-scenes", type=int, default=None,
                       help="æœ€å¤§å¤„ç†åœºæ™¯æ•°ï¼ˆç”¨äºæµ‹è¯•ï¼‰")
    
    args = parser.parse_args()
    
    # éªŒè¯åˆ†å¸ƒå¼å‚æ•°
    if (args.worker_id is None) != (args.total_workers is None):
        parser.error("--worker-id å’Œ --total-workers å¿…é¡»åŒæ—¶æä¾›æˆ–åŒæ—¶çœç•¥")
    
    if args.worker_id is not None and args.total_workers is not None:
        if args.worker_id >= args.total_workers or args.worker_id < 0:
            parser.error(f"worker_id {args.worker_id} å¿…é¡»åœ¨ 0 åˆ° {args.total_workers-1} ä¹‹é—´")
    
    print("="*80)
    print("ğŸš€ CA-1Mæ•°æ®é›†åˆ†å¸ƒå¼å¤šçº¿ç¨‹å¤„ç†å·¥å…·")
    print("="*80)
    print(f"ğŸ“ æ•°æ®ç›®å½•: {args.data_dir}")
    print(f"ğŸ“¤ è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"ğŸ“Š å¤„ç†åˆ’åˆ†: {args.split}")
    
    # åˆ†å¸ƒå¼ä¿¡æ¯
    if args.worker_id is not None:
        print(f"ğŸ¤– åˆ†å¸ƒå¼æ¨¡å¼: Worker {args.worker_id}/{args.total_workers}")
    else:
        print("ğŸ  å•æœºæ¨¡å¼: å¤„ç†å…¨éƒ¨æ•°æ®")
    
    # çº¿ç¨‹é…ç½®
    print(f"ğŸ§® è®¡ç®—çº¿ç¨‹æ•°: {args.compute_workers}")
    print(f"ğŸ’¾ I/Oçº¿ç¨‹æ•°: {args.io_workers}")
    print(f"ğŸ¬ åœºæ™¯å¤„ç†çº¿ç¨‹æ•°: {args.scene_workers}")
    
    if args.disable_downsampling:
        print("ğŸ“¦ ä½“ç´ ä¸‹é‡‡æ ·: ç¦ç”¨")
    else:
        print(f"ğŸ“¦ ä½“ç´ ä¸‹é‡‡æ ·å°ºå¯¸: {args.voxel_size}m")
    print("="*80)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    split_output_dir = os.path.join(args.output_dir, args.split)
    if args.worker_id is not None:
        # ä¸ºæ¯ä¸ªworkeråˆ›å»ºå•ç‹¬çš„è¾“å‡ºç›®å½•
        split_output_dir = os.path.join(split_output_dir, f"worker_{args.worker_id}")
    os.makedirs(split_output_dir, exist_ok=True)
    
    # è·å–åœºæ™¯æ–‡ä»¶åˆ—è¡¨ï¼ˆæ”¯æŒåˆ†å¸ƒå¼ï¼‰
    try:
        scene_files = get_scene_files(args.data_dir, args.split, args.worker_id, args.total_workers)
    except ValueError as e:
        print(f"âŒ é”™è¯¯: {e}")
        sys.exit(1)
    
    # é™åˆ¶åœºæ™¯æ•°é‡ï¼ˆç”¨äºæµ‹è¯•ï¼‰
    if args.max_scenes is not None:
        scene_files = scene_files[:args.max_scenes]
        print(f"ğŸ”¬ æµ‹è¯•æ¨¡å¼: ä»…å¤„ç†å‰ {len(scene_files)} ä¸ªåœºæ™¯")
    
    # è®¾ç½®ä¸‹é‡‡æ ·å‚æ•°
    voxel_size = 0 if args.disable_downsampling else args.voxel_size
    
    # å¤šçº¿ç¨‹å¤„ç†åœºæ™¯
    total_start_time = time.time()
    successful_scenes = []
    failed_scenes = []
    
    print(f"\nğŸ¬ å¼€å§‹å¤šçº¿ç¨‹å¤„ç† {len(scene_files)} ä¸ªåœºæ™¯...")
    
    with ThreadPoolExecutor(max_workers=args.scene_workers, thread_name_prefix="Scene") as executor:
        # æäº¤æ‰€æœ‰åœºæ™¯å¤„ç†ä»»åŠ¡
        future_to_scene = {}
        for scene_file in scene_files:
            future = executor.submit(
                process_single_scene,
                scene_file,
                split_output_dir,
                voxel_size,
                args.compute_workers,
                args.io_workers
            )
            future_to_scene[future] = scene_file
        
        # æ”¶é›†ç»“æœ
        for future in as_completed(future_to_scene):
            scene_file = future_to_scene[future]
            try:
                result = future.result()
                successful_scenes.append(result)
                print(f"âœ… åœºæ™¯ {result[0]} å¤„ç†æˆåŠŸ")
            except Exception as e:
                failed_scenes.append((Path(scene_file).stem, str(e)))
                print(f"âŒ åœºæ™¯ {Path(scene_file).stem} å¤„ç†å¤±è´¥: {e}")
    
    # æ€»ç»“æŠ¥å‘Š
    total_time = time.time() - total_start_time
    print("\n" + "="*80)
    if args.worker_id is not None:
        print(f"ğŸ“Š Worker {args.worker_id} å¤„ç†å®Œæˆç»Ÿè®¡æŠ¥å‘Š")
    else:
        print("ğŸ“Š å¤„ç†å®Œæˆç»Ÿè®¡æŠ¥å‘Š")
    print("="*80)
    print(f"ğŸ•’ æ€»å¤„ç†æ—¶é—´: {total_time:.2f}ç§’")
    print(f"âœ… æˆåŠŸå¤„ç†åœºæ™¯: {len(successful_scenes)} ä¸ª")
    print(f"âŒ å¤±è´¥åœºæ™¯: {len(failed_scenes)} ä¸ª")
    
    if successful_scenes:
        total_frames = sum(result[2] for result in successful_scenes)
        total_instances = sum(result[3] for result in successful_scenes)
        print(f"ğŸ“Š æ€»å¤„ç†å¸§æ•°: {total_frames}")
        print(f"ğŸ¯ æ€»å®ä¾‹æ•°: {total_instances}")
        print(f"âš¡ å¹³å‡æ¯åœºæ™¯å¤„ç†æ—¶é—´: {sum(result[1] for result in successful_scenes)/len(successful_scenes):.2f}ç§’")
        
        if len(scene_files) > 0:
            throughput = len(successful_scenes) / total_time * 3600  # åœºæ™¯/å°æ—¶
            print(f"ğŸš€ å¤„ç†ååé‡: {throughput:.1f} åœºæ™¯/å°æ—¶")
    
    if failed_scenes:
        print("\nâŒ å¤±è´¥åœºæ™¯åˆ—è¡¨:")
        for scene_name, error in failed_scenes:
            print(f"  - {scene_name}: {error}")
    
    print(f"\nğŸ“ è¾“å‡ºç›®å½•: {split_output_dir}")
    
    # åˆ†å¸ƒå¼å¤„ç†æç¤º
    if args.worker_id is not None:
        print(f"\nğŸ’¡ åˆ†å¸ƒå¼å¤„ç†æç¤º:")
        print(f"   - å½“å‰Worker: {args.worker_id}/{args.total_workers}")
        print(f"   - å…¶ä»–workerè¯·ä½¿ç”¨ä¸åŒçš„worker-id (0-{args.total_workers-1})")
        print(f"   - æ‰€æœ‰workerå®Œæˆåï¼Œå¯åˆå¹¶ worker_* ç›®å½•ä¸‹çš„ç»“æœ")
    
    print("="*80)

if __name__ == "__main__":
    main()
